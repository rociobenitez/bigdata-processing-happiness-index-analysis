# Introducci√≥n a Hadoop: Manipulaci√≥n de Datos con HDFS

[Hadoop](https://hadoop.apache.org/) es un framework de c√≥digo abierto que permite el ***procesamiento y almacenamiento distribuido de grandes conjuntos de datos en cl√∫steres de servidores***. Uno de los componentes centrales de Hadoop es el **Sistema de Archivos Distribuido Hadoop (HDFS)**, que permite el almacenamiento y la recuperaci√≥n eficiente de datos en un entorno de cl√∫ster. Vamos a explorar los conceptos b√°sicos de HDFS y c√≥mo interactuar con √©l a trav√©s de la l√≠nea de comandos.

## Caracter√≠sticas üìù

- **Distribuido y Escalable:** los datos y su procesamiento se distribuyen sobre un cl√∫ster de ordenadores (escalado horizontal), desde un √∫nico servidor a miles de m√°quinas.
- **Tolerante a fallos:** tras detectar un fallo aplica una recuperaci√≥n autom√°tica.
- **Open-source**
- **Confiable:** crea m√∫ltiples copias de los datos de manera autom√°tica.
- **Portable:** se puede instalar en todo tipo de hardware y sistemas operativos.

## Procesamiento distribuido üîÄ

Hadoop sigue un enfoque donde guarda y procesa datos en el mismo lugar, evitando trasladar los datos al sistema de procesamiento. Esto se logra mediante un sistema distribuido con dos tipos de nodos:

1. **Nodos maestros**: Controlan la gesti√≥n global, supervisan los trabajos y datos. Por lo general, se utilizan 3 de ellos con hardware m√°s robusto.

2. **Nodos workers**: Manejan datos locales y procesamiento de aplicaciones. El n√∫mero var√≠a seg√∫n las necesidades, desde 4 hasta miles, con hardware econ√≥mico tipo servidor X86.

Adem√°s, existen los **nodos edge** que act√∫an como intermediarios entre el cl√∫ster y la red externa, proporcionando interfaces de comunicaci√≥n.

Cada vez que a√±adimos un nuevo nodo worker, aumentamos tanto la capacidad como el rendimiento de nuestro sistema.

## Enlaces de inter√©s para empezar a utilizar Hadoop üîó

- [Amazon Elastic MapReduce(EMR)](https://aws.amazon.com/es/emr/) de AWS
- [CDH](https://www.cloudera.com/products/open-source/apache-hadoop/key-cdh-components.html) de Cloudera
- [Dataproc](https://cloud.google.com/dataproc?hl=es) de Google
- [Azure HDInsight](https://azure.microsoft.com/es-es/products/hdinsight/) de Microsoft


## HDFS üíª

Divide los archivos en bloques y los replica en m√∫ltiples nodos para garantizar la redundancia y la disponibilidad. Est√° optimizado para escrituras √∫nicas y lecturas m√∫ltiples, y es **ideal para datos de entrada** utilizados en procesos de c√≥mputo.

**No ofrece buen rendimiento para:**
- Acceder a datos de baja latencia
- Manejar ficheros peque√±os
- M√∫ltiples escritores
- Modificaciones arbitrarias de ficheros

Los datos, una vez escritos en HDFS son **immutables**. Cada fichero de HDFS solo permite a√±adir contenido *(append-only)*. Una vez se ha creado y escrito en √©l, solo podemos a√±adir contenido o eliminarlo. Es decir, a priori, no podemos modificar los datos.

*HBase* y *Hive* son soluciones que se construyen sobre HDFS y permiten la modificaci√≥n de datos, lo que lo convierte en una capa de almacenamiento m√°s vers√°til.

## Bloques üß±

Los bloques en HDFS son ***unidades de datos m√≠nimas que se leen o escriben***, generalmente de **128 MB** de tama√±o. Los archivos se dividen en bloques, y si un archivo es m√°s peque√±o que el tama√±o del bloque, ocupar√° solo el espacio necesario en disco.

Adem√°s, los bloques se replican para garantizar la redundancia y la disponibilidad, con un valor predeterminado de *replicaci√≥n de 3*, lo que significa que un archivo de 600 MB, dividido en 5 bloques, se almacena en 15 bloques en diferentes nodos del cl√∫ster.

En HDFS, se pueden identificar **tres tipos de m√°quinas**:

1. **Namenode:** Act√∫a como el servidor principal y almacena los metadatos para construir el sistema de archivos a partir de bloques. Controla la ubicaci√≥n de todos los bloques.

2. **Datanode:** Son los nodos esclavos que almacenan los bloques que componen cada archivo.

3. **Secondary Namenode:** Su funci√≥n principal es tomar puntos de control de los metadatos del sistema de archivos presentes en el Namenode.

M√°s informaci√≥n sobre la arquitectura de HDFS en [HDFS-Namenodes-Datanodes.md](/Main-insights-and-learnings/5-Hadoop/5-HDFS-Namenodes-Datanodes.md).

## Instalaci√≥n üë©üèº‚Äçüíª

Mi intento de [instalar Hadoop localmente en macOS](/Main-insights-and-learnings/5-Hadoop/3-Instalar-Hadoop-Mac.md) se convirti√≥ en un desaf√≠o, ya que me encontr√© con varias dificultades. Una de las principales complicaciones fue el error *"Failed to retrieve data from /webhdfs/v1/?op=LISTSTATUS: Server Error"* al usar la interfaz web de Hadoop. Investigando, descubr√≠ que este problema podr√≠a estar relacionado con una versi√≥n de Java incompatible, especialmente si se ten√≠a una versi√≥n superior a Java 11, como se menciona en la documentaci√≥n de Hadoop.

Despu√©s de luchar con estos problemas, decid√≠ cambiar mi enfoque y opt√© por [instalar Hadoop en Docker](/Main-insights-and-learnings/5-Hadoop/3-Instalar-Hadoop-Docker.md). Esta elecci√≥n result√≥ ser m√°s sencilla y efectiva, permiti√©ndome evitar los obst√°culos que encontr√© al intentar una instalaci√≥n local.

## Sintaxis B√°sica de un Comando HDFS ‚å®Ô∏è

Antes de sumergirnos en la manipulaci√≥n de archivos en HDFS, es importante comprender la sintaxis b√°sica de un comando HDFS. Los comandos de HDFS siguen la siguiente estructura:

```
hdfs dfs comando parametros_del_comando
```

Donde:

- `hdfs` indica que estamos utilizando la consola de HDFS.
- `dfs` indica que queremos manipular los archivos en HDFS (dfs = distribuited filesystem).
- `comando` es el comando que deseamos ejecutar en HDFS, como por ejemplo el comando `-ls` que se utiliza para listar el contenido de una carpeta en HDFS.
- `par√°metros_del_comando` son los par√°metros asociados al comando, por ejemplo, si el comando fuera `-mkdir`, el par√°metro ser√≠a el nombre de la carpeta que se crea.

## La Carpeta Ra√≠z de HDFS

HDFS es un sistema de archivos distribuido, lo que significa que tiene una carpeta ra√≠z `/` donde se encuentran todas las dem√°s carpetas y archivos. La carpeta ra√≠z se representa con una barra diagonal.

## Listar el Contenido de una Carpeta

Para listar el contenido de una carpeta en HDFS, utilizamos el comando `-ls`. Por ejemplo:

```
hdfs dfs -ls /
```

Este comando listar√° el contenido de la carpeta ra√≠z de HDFS, mostrando informaci√≥n sobre los archivos y subcarpetas presentes.

## Creaci√≥n de Carpetas

Puedes crear una carpeta en HDFS con el comando `-mkdir`. Por ejemplo:

```
hdfs dfs -mkdir /example/carpeta1
```

Este comando crea una carpeta llamada `carpeta1` dentro de la carpeta `/example` en HDFS.

Si deseas crear una carpeta y sus subcarpetas de manera recursiva, puedes usar la opci√≥n `-p`, como se muestra a continuaci√≥n:

```
hdfs dfs -mkdir -p /example/carpeta2/carpetaA/carpetaB/carpetaC
```

Este comando crea toda la estructura de carpetas, incluidas las subcarpetas, si no existen.

## Creaci√≥n de un Archivo Vac√≠o

Puedes crear un archivo vac√≠o en HDFS con el comando `-touchz`. Por ejemplo:

```
hdfs dfs -touchz /example/archivo_vacio.txt
```

Este comando crea un archivo vac√≠o llamado `archivo_vacio.txt` en la carpeta `/example` en HDFS.

## Subiendo Archivos a HDFS

HDFS te permite subir archivos desde tu sistema local al sistema distribuido. Puedes usar el comando `-put` para lograrlo. Por ejemplo:

```
hdfs dfs -put /ruta/archivo_local.txt /example/
```

Este comando sube el archivo local `archivo_local.txt` a la carpeta `/example` en HDFS.

## Viendo el Contenido de los Archivos

Para ver el contenido de un archivo en HDFS, utiliza el comando `-cat`. Por ejemplo:

```
hdfs dfs -cat /example/archivo_vacio.txt
```

Este comando muestra el contenido del archivo `archivo_vacio.txt` en la carpeta `/example` de HDFS.

## Eliminando Recursos en HDFS

Puedes eliminar archivos y carpetas en HDFS utilizando el comando `-rm`. Por ejemplo, para eliminar un archivo:

```
hdfs dfs -rm /example/archivo_vacio.txt
```

Para eliminar recursos que cumplan un patr√≥n, puedes utilizar el comod√≠n `*`. Por ejemplo:

```
hdfs dfs -rm /example/transacciones*.data
```

Este comando eliminar√° todos los archivos en la carpeta `/example` que coincidan con el patr√≥n `transacciones*.data`.

Para eliminar una carpeta y su contenido de manera recursiva, utiliza el comando `-rm -r -f`. Por ejemplo:

```
hdfs dfs -rm -r -f /example/carpeta1
```

Este comando eliminar√° la carpeta `carpeta1` y todo su contenido de manera recursiva.

## Conclusion

**HDFS** es un componente fundamental de Hadoop que permite el almacenamiento y la gesti√≥n de grandes vol√∫menes de datos de manera distribuida. Con los comandos b√°sicos de HDFS, puedes manipular archivos y carpetas de manera eficiente en un entorno de cl√∫ster.